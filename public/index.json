[{"authors":["admin"],"categories":null,"content":"\rThe URL of this page is going to change soon!\n\r\r-- My name is Kleanthis Natsiopoulos. I live in Greece and my academic background is in Economics and Statistics, while I have worked as a Data Analyst in the oil and shipping industry. Currently, I am a Ph.D. Candidate in Economics at the University of Thessaly. My broad research interests include econometrics, machine learning, computational economics, statistics but most of all the combination of the above.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"The URL of this page is going to change soon!\n\r\r-- My name is Kleanthis Natsiopoulos. I live in Greece and my academic background is in Economics and Statistics, while I have worked as a Data Analyst in the oil and shipping industry. Currently, I am a Ph.D. Candidate in Economics at the University of Thessaly. My broad research interests include econometrics, machine learning, computational economics, statistics but most of all the combination of the above.","tags":null,"title":"Kleanthis Natsiopoulos","type":"author"},{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536440400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536440400,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"/tutorial/","publishdate":"2018-09-09T00:00:00+03:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":[],"content":"\rI am glad to anounce that my new ARDL package has been published on CRAN! This is part of my Ph.D. at the University of Thessaly under the supervision of the Associate Professor Nickolaos Tzeremes.\nThe ARDL package functionality consists mainly of three things (more to come in future updates):\nDynamic time-series regression models (ARDL and ECM)\n\rBounds-test for cointegration (Pesaran et al. (2001))\n\rLong-run multipliers (short-run and interim multipliers are comming in the next update)\n\r\rThe first one provides an easy and straight forward way to construct complex Autoregressive Distributed Lag (ARDL) and Error Correction Models (ECM). But most of all, it ensures the accuracy and the quality of the resulted models! This can be achieved as it is not prompt to user errors and doesn’t expect from the user to know the exact technical details of the model specification. The only thing the user has to do is to set the type of the model and the appropriate model specification will be automatically computed.\nE.g. an ARDL model can be explicitly described by its order, say ARDL(3,1,3,2). So the user asks for an ARDL(3,1,3,2) without having to know its structure which would be of the following form (assuming a constant and linear trend as an example):\n\\[y_{t} = c_{0} + c_{1}t + \\sum_{i=1}^{3}b_{y,i}y_{t-i} + \\sum_{j=1}^{3}\\sum_{l=0}^{q_{j}}b_{j,l}x_{j,t-l} + \\epsilon_{t}\\]\n\\[where \\; q_{1}=1, q_{2}=3, q_{3}=2\\]\nMore about this topic and the usage of multipliers will follow in next posts.\nPart 1, focuses on the other main functionality of the package. The bounds-test.\nBounds-test for cointegration\rIt refers to the famous test1 proposed by Pesaran, Shin and Smith (2001).\nThe rising usage of the test and the fact that there was not yet (despite the vast demand of the test) a complete and reliable package for this purpose in R, led me to create it!2.\nSo let’s take a quick look on the advantages of using the ARDL package to perform the bounds-test.\n\rAdvantages\r1. The reliable underlying models\rThe main building block to perform the bounds-test is the conditional ECM of the underlying ARDL model, as the test itself is actually a joint wald-test on some parameters of the ECM. So having a correctly specified ARDL model and its conditional ECM is essential in order to proceed to the test!\nLuckily, this is exactly what the ARDL package does!\n\r2. Both the F-test and the t-test are available\rThe bounds-test consists of two tests, the F-test and the t-test. The t-test is a subset of the F-test and both of them have to be performed in order to have a clear conclusion.\n\r3. P-values and critical value bounds\rThe bounds-test is already available in some commercial software. Although, they only provide the critical value bounds for a specific level of statistical significance, but sadly the usual case is that only the 1%, 5% and 10% levels of significance are available. The ARDL package provides critical value bounds for any significance level!\nMore over, p-values are available in the ARDL package!\n\r4. Exact sample and asymptotic tests\rAgain, in comparison with other commercial and non-commercial software that only provide asymptotic results, the ARDL package also provides exact sample p-values and critical value bounds! This is useful in cases where we have limited data. The asymptotic results (offered by Pesaran et al. (2001)) assume that our dataset consists of 1000 observations. The truth is that in economics, social science etc we don’t have time-series that long. We usually have much less than this (e.g. series like the GDP is hard to be more than 100 observations long), and in this case the problem is even more severe as the asymptotic results would be very far from the truth.\n\r5. Cointegrating equation (long-run relationship)\rAlso, the user can extract the long-run relationship (cointegrating equation) and examine how this fits the original data and graphically check for a degenerate relationship, that can’t be seen using just the test.\n\r\rConclusion\rThis is just one of the package features and just few of its advantages are mentioned here.\nExplore more in the README file!\nFeel free to leave a comment below or contact me via e-mail, linkedin or twitter to request an extra functionality to be included in the pacakge, report any bug or error, or just express your experience using the package!\nIf you use ARDL in your publications, please cite as:\nNatsiopoulos K, Tzeremes N (2020). ARDL: ARDL, ECM and Bounds-Test for Cointegration. Ph.D. thesis, University of Thessaly, Department of Economics. R package version 0.1.0\n\rWhy to use the ARDL package in your publications\rProbably the most valuable part of the pacakge. The answer is coming soon in a future update! Stay tuned!\n\rReferences\rPesaran, M. H., Shin, Y., \u0026amp; Smith, R. J. (2001). Bounds testing approaches to the analysis of level relationships. Journal of Applied Econometrics, 16(3), 289-326\n\r\r11664 citations on Google Scholar by the time of this post.↩\n\rNote that there are a few packages (on CRAN or in github repos) that provide the test but as we said… completeness and reliability of results!↩\n\r\r\r","date":1586736000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586736000,"objectID":"c328ef89167334aaf709945a13c7fda2","permalink":"/post/ardl-pkg-part1/ardl-pkg-part1/","publishdate":"2020-04-13T00:00:00Z","relpermalink":"/post/ardl-pkg-part1/ardl-pkg-part1/","section":"post","summary":"The advantages of using the new 'ARDL' R package for the bounds-test for cointegration.","tags":["R","econometrics"],"title":"The new 'ARDL' R package. Part 1: Bounds-test advantages","type":"post"},{"authors":null,"categories":[],"content":"\r\rIt all started when I was trying to do some joint restriction on the regression’s coefficients… in Julia… and I failed… And this is because there is no function (at least yet) to perform a Wald test on the estimated regression model. So I made it! In short, I just rewrote the wald.test function from the aod package in R, and created a new function for Julia. It’s called, guess what… wald_test.\nFor those already familiar with the wald.test from the aod package in R, the wald_test function in Julia works exactly the same way. For anyone who is interested, you can download the Julia function from my GitHub repo.\nThe rest of the article shows some examples of regression coefficient restrictions using the wald test, first implementing in R and then in Julia.\nThe first example is a simple joint restriction.\rIn the second example we also jointly restrict all the regression coefficients except of the intercept to 0, which is practically the standard F test of a regression.\rFinally, in the third example, we include the intercept in the restricted coefficients.\r\rThrough these examples, we explore the relationship between the F and the \\(\\chi^2\\) distribution, we solve a single problem using 2 different tests (ANOVA (F-test) and Wald (\\(\\chi^2\\)-test)) and we will also show how these tests do not always both work, and this is how the need for this function in Julia was born.\nPackages and data\rFirst things first. Let’s get ready with the packages and the data we are going to use.\nIn R, the dataset iris is already loaded in the object iris and we will also need the package aod which contains the wald.test function.\nIn Julia, we will need to load the package RDatasets for the iris dataset, the package DataFrames in order to work with dataframes and the package GLM for the ftest function.\nOh, and don’t forget our new function wald_test! Assuming you have already downloaded the wald_test.jl file, all you have to do is to load it too1.\nR:\nlibrary(aod)\r\r\rSepal.Length\r\rSepal.Width\r\rPetal.Length\r\rPetal.Width\r\rSpecies\r\r\r\r\r\r5.1\r\r3.5\r\r1.4\r\r0.2\r\rsetosa\r\r\r\r4.9\r\r3.0\r\r1.4\r\r0.2\r\rsetosa\r\r\r\r4.7\r\r3.2\r\r1.3\r\r0.2\r\rsetosa\r\r\r\r4.6\r\r3.1\r\r1.5\r\r0.2\r\rsetosa\r\r\r\r5.0\r\r3.6\r\r1.4\r\r0.2\r\rsetosa\r\r\r\r5.4\r\r3.9\r\r1.7\r\r0.4\r\rsetosa\r\r\r\r4.6\r\r3.4\r\r1.4\r\r0.3\r\rsetosa\r\r\r\r5.0\r\r3.4\r\r1.5\r\r0.2\r\rsetosa\r\r\r\r4.4\r\r2.9\r\r1.4\r\r0.2\r\rsetosa\r\r\r\r4.9\r\r3.1\r\r1.5\r\r0.1\r\rsetosa\r\r\r\r5.4\r\r3.7\r\r1.5\r\r0.2\r\rsetosa\r\r\r\r4.8\r\r3.4\r\r1.6\r\r0.2\r\rsetosa\r\r\r\r4.8\r\r3.0\r\r1.4\r\r0.1\r\rsetosa\r\r\r\r4.3\r\r3.0\r\r1.1\r\r0.1\r\rsetosa\r\r\r\r5.8\r\r4.0\r\r1.2\r\r0.2\r\rsetosa\r\r\r\r5.7\r\r4.4\r\r1.5\r\r0.4\r\rsetosa\r\r\r\r5.4\r\r3.9\r\r1.3\r\r0.4\r\rsetosa\r\r\r\r5.1\r\r3.5\r\r1.4\r\r0.3\r\rsetosa\r\r\r\r5.7\r\r3.8\r\r1.7\r\r0.3\r\rsetosa\r\r\r\r5.1\r\r3.8\r\r1.5\r\r0.3\r\rsetosa\r\r\r\r5.4\r\r3.4\r\r1.7\r\r0.2\r\rsetosa\r\r\r\r5.1\r\r3.7\r\r1.5\r\r0.4\r\rsetosa\r\r\r\r4.6\r\r3.6\r\r1.0\r\r0.2\r\rsetosa\r\r\r\r5.1\r\r3.3\r\r1.7\r\r0.5\r\rsetosa\r\r\r\r4.8\r\r3.4\r\r1.9\r\r0.2\r\rsetosa\r\r\r\r5.0\r\r3.0\r\r1.6\r\r0.2\r\rsetosa\r\r\r\r5.0\r\r3.4\r\r1.6\r\r0.4\r\rsetosa\r\r\r\r5.2\r\r3.5\r\r1.5\r\r0.2\r\rsetosa\r\r\r\r5.2\r\r3.4\r\r1.4\r\r0.2\r\rsetosa\r\r\r\r4.7\r\r3.2\r\r1.6\r\r0.2\r\rsetosa\r\r\r\r4.8\r\r3.1\r\r1.6\r\r0.2\r\rsetosa\r\r\r\r5.4\r\r3.4\r\r1.5\r\r0.4\r\rsetosa\r\r\r\r5.2\r\r4.1\r\r1.5\r\r0.1\r\rsetosa\r\r\r\r5.5\r\r4.2\r\r1.4\r\r0.2\r\rsetosa\r\r\r\r4.9\r\r3.1\r\r1.5\r\r0.2\r\rsetosa\r\r\r\r5.0\r\r3.2\r\r1.2\r\r0.2\r\rsetosa\r\r\r\r5.5\r\r3.5\r\r1.3\r\r0.2\r\rsetosa\r\r\r\r4.9\r\r3.6\r\r1.4\r\r0.1\r\rsetosa\r\r\r\r4.4\r\r3.0\r\r1.3\r\r0.2\r\rsetosa\r\r\r\r5.1\r\r3.4\r\r1.5\r\r0.2\r\rsetosa\r\r\r\r5.0\r\r3.5\r\r1.3\r\r0.3\r\rsetosa\r\r\r\r4.5\r\r2.3\r\r1.3\r\r0.3\r\rsetosa\r\r\r\r4.4\r\r3.2\r\r1.3\r\r0.2\r\rsetosa\r\r\r\r5.0\r\r3.5\r\r1.6\r\r0.6\r\rsetosa\r\r\r\r5.1\r\r3.8\r\r1.9\r\r0.4\r\rsetosa\r\r\r\r4.8\r\r3.0\r\r1.4\r\r0.3\r\rsetosa\r\r\r\r5.1\r\r3.8\r\r1.6\r\r0.2\r\rsetosa\r\r\r\r4.6\r\r3.2\r\r1.4\r\r0.2\r\rsetosa\r\r\r\r5.3\r\r3.7\r\r1.5\r\r0.2\r\rsetosa\r\r\r\r5.0\r\r3.3\r\r1.4\r\r0.2\r\rsetosa\r\r\r\r7.0\r\r3.2\r\r4.7\r\r1.4\r\rversicolor\r\r\r\r6.4\r\r3.2\r\r4.5\r\r1.5\r\rversicolor\r\r\r\r6.9\r\r3.1\r\r4.9\r\r1.5\r\rversicolor\r\r\r\r5.5\r\r2.3\r\r4.0\r\r1.3\r\rversicolor\r\r\r\r6.5\r\r2.8\r\r4.6\r\r1.5\r\rversicolor\r\r\r\r5.7\r\r2.8\r\r4.5\r\r1.3\r\rversicolor\r\r\r\r6.3\r\r3.3\r\r4.7\r\r1.6\r\rversicolor\r\r\r\r4.9\r\r2.4\r\r3.3\r\r1.0\r\rversicolor\r\r\r\r6.6\r\r2.9\r\r4.6\r\r1.3\r\rversicolor\r\r\r\r5.2\r\r2.7\r\r3.9\r\r1.4\r\rversicolor\r\r\r\r5.0\r\r2.0\r\r3.5\r\r1.0\r\rversicolor\r\r\r\r5.9\r\r3.0\r\r4.2\r\r1.5\r\rversicolor\r\r\r\r6.0\r\r2.2\r\r4.0\r\r1.0\r\rversicolor\r\r\r\r6.1\r\r2.9\r\r4.7\r\r1.4\r\rversicolor\r\r\r\r5.6\r\r2.9\r\r3.6\r\r1.3\r\rversicolor\r\r\r\r6.7\r\r3.1\r\r4.4\r\r1.4\r\rversicolor\r\r\r\r5.6\r\r3.0\r\r4.5\r\r1.5\r\rversicolor\r\r\r\r5.8\r\r2.7\r\r4.1\r\r1.0\r\rversicolor\r\r\r\r6.2\r\r2.2\r\r4.5\r\r1.5\r\rversicolor\r\r\r\r5.6\r\r2.5\r\r3.9\r\r1.1\r\rversicolor\r\r\r\r5.9\r\r3.2\r\r4.8\r\r1.8\r\rversicolor\r\r\r\r6.1\r\r2.8\r\r4.0\r\r1.3\r\rversicolor\r\r\r\r6.3\r\r2.5\r\r4.9\r\r1.5\r\rversicolor\r\r\r\r6.1\r\r2.8\r\r4.7\r\r1.2\r\rversicolor\r\r\r\r6.4\r\r2.9\r\r4.3\r\r1.3\r\rversicolor\r\r\r\r6.6\r\r3.0\r\r4.4\r\r1.4\r\rversicolor\r\r\r\r6.8\r\r2.8\r\r4.8\r\r1.4\r\rversicolor\r\r\r\r6.7\r\r3.0\r\r5.0\r\r1.7\r\rversicolor\r\r\r\r6.0\r\r2.9\r\r4.5\r\r1.5\r\rversicolor\r\r\r\r5.7\r\r2.6\r\r3.5\r\r1.0\r\rversicolor\r\r\r\r5.5\r\r2.4\r\r3.8\r\r1.1\r\rversicolor\r\r\r\r5.5\r\r2.4\r\r3.7\r\r1.0\r\rversicolor\r\r\r\r5.8\r\r2.7\r\r3.9\r\r1.2\r\rversicolor\r\r\r\r6.0\r\r2.7\r\r5.1\r\r1.6\r\rversicolor\r\r\r\r5.4\r\r3.0\r\r4.5\r\r1.5\r\rversicolor\r\r\r\r6.0\r\r3.4\r\r4.5\r\r1.6\r\rversicolor\r\r\r\r6.7\r\r3.1\r\r4.7\r\r1.5\r\rversicolor\r\r\r\r6.3\r\r2.3\r\r4.4\r\r1.3\r\rversicolor\r\r\r\r5.6\r\r3.0\r\r4.1\r\r1.3\r\rversicolor\r\r\r\r5.5\r\r2.5\r\r4.0\r\r1.3\r\rversicolor\r\r\r\r5.5\r\r2.6\r\r4.4\r\r1.2\r\rversicolor\r\r\r\r6.1\r\r3.0\r\r4.6\r\r1.4\r\rversicolor\r\r\r\r5.8\r\r2.6\r\r4.0\r\r1.2\r\rversicolor\r\r\r\r5.0\r\r2.3\r\r3.3\r\r1.0\r\rversicolor\r\r\r\r5.6\r\r2.7\r\r4.2\r\r1.3\r\rversicolor\r\r\r\r5.7\r\r3.0\r\r4.2\r\r1.2\r\rversicolor\r\r\r\r5.7\r\r2.9\r\r4.2\r\r1.3\r\rversicolor\r\r\r\r6.2\r\r2.9\r\r4.3\r\r1.3\r\rversicolor\r\r\r\r5.1\r\r2.5\r\r3.0\r\r1.1\r\rversicolor\r\r\r\r5.7\r\r2.8\r\r4.1\r\r1.3\r\rversicolor\r\r\r\r6.3\r\r3.3\r\r6.0\r\r2.5\r\rvirginica\r\r\r\r5.8\r\r2.7\r\r5.1\r\r1.9\r\rvirginica\r\r\r\r7.1\r\r3.0\r\r5.9\r\r2.1\r\rvirginica\r\r\r\r6.3\r\r2.9\r\r5.6\r\r1.8\r\rvirginica\r\r\r\r6.5\r\r3.0\r\r5.8\r\r2.2\r\rvirginica\r\r\r\r7.6\r\r3.0\r\r6.6\r\r2.1\r\rvirginica\r\r\r\r4.9\r\r2.5\r\r4.5\r\r1.7\r\rvirginica\r\r\r\r7.3\r\r2.9\r\r6.3\r\r1.8\r\rvirginica\r\r\r\r6.7\r\r2.5\r\r5.8\r\r1.8\r\rvirginica\r\r\r\r7.2\r\r3.6\r\r6.1\r\r2.5\r\rvirginica\r\r\r\r6.5\r\r3.2\r\r5.1\r\r2.0\r\rvirginica\r\r\r\r6.4\r\r2.7\r\r5.3\r\r1.9\r\rvirginica\r\r\r\r6.8\r\r3.0\r\r5.5\r\r2.1\r\rvirginica\r\r\r\r5.7\r\r2.5\r\r5.0\r\r2.0\r\rvirginica\r\r\r\r5.8\r\r2.8\r\r5.1\r\r2.4\r\rvirginica\r\r\r\r6.4\r\r3.2\r\r5.3\r\r2.3\r\rvirginica\r\r\r\r6.5\r\r3.0\r\r5.5\r\r1.8\r\rvirginica\r\r\r\r7.7\r\r3.8\r\r6.7\r\r2.2\r\rvirginica\r\r\r\r7.7\r\r2.6\r\r6.9\r\r2.3\r\rvirginica\r\r\r\r6.0\r\r2.2\r\r5.0\r\r1.5\r\rvirginica\r\r\r\r6.9\r\r3.2\r\r5.7\r\r2.3\r\rvirginica\r\r\r\r5.6\r\r2.8\r\r4.9\r\r2.0\r\rvirginica\r\r\r\r7.7\r\r2.8\r\r6.7\r\r2.0\r\rvirginica\r\r\r\r6.3\r\r2.7\r\r4.9\r\r1.8\r\rvirginica\r\r\r\r6.7\r\r3.3\r\r5.7\r\r2.1\r\rvirginica\r\r\r\r7.2\r\r3.2\r\r6.0\r\r1.8\r\rvirginica\r\r\r\r6.2\r\r2.8\r\r4.8\r\r1.8\r\rvirginica\r\r\r\r6.1\r\r3.0\r\r4.9\r\r1.8\r\rvirginica\r\r\r\r6.4\r\r2.8\r\r5.6\r\r2.1\r\rvirginica\r\r\r\r7.2\r\r3.0\r\r5.8\r\r1.6\r\rvirginica\r\r\r\r7.4\r\r2.8\r\r6.1\r\r1.9\r\rvirginica\r\r\r\r7.9\r\r3.8\r\r6.4\r\r2.0\r\rvirginica\r\r\r\r6.4\r\r2.8\r\r5.6\r\r2.2\r\rvirginica\r\r\r\r6.3\r\r2.8\r\r5.1\r\r1.5\r\rvirginica\r\r\r\r6.1\r\r2.6\r\r5.6\r\r1.4\r\rvirginica\r\r\r\r7.7\r\r3.0\r\r6.1\r\r2.3\r\rvirginica\r\r\r\r6.3\r\r3.4\r\r5.6\r\r2.4\r\rvirginica\r\r\r\r6.4\r\r3.1\r\r5.5\r\r1.8\r\rvirginica\r\r\r\r6.0\r\r3.0\r\r4.8\r\r1.8\r\rvirginica\r\r\r\r6.9\r\r3.1\r\r5.4\r\r2.1\r\rvirginica\r\r\r\r6.7\r\r3.1\r\r5.6\r\r2.4\r\rvirginica\r\r\r\r6.9\r\r3.1\r\r5.1\r\r2.3\r\rvirginica\r\r\r\r5.8\r\r2.7\r\r5.1\r\r1.9\r\rvirginica\r\r\r\r6.8\r\r3.2\r\r5.9\r\r2.3\r\rvirginica\r\r\r\r6.7\r\r3.3\r\r5.7\r\r2.5\r\rvirginica\r\r\r\r6.7\r\r3.0\r\r5.2\r\r2.3\r\rvirginica\r\r\r\r6.3\r\r2.5\r\r5.0\r\r1.9\r\rvirginica\r\r\r\r6.5\r\r3.0\r\r5.2\r\r2.0\r\rvirginica\r\r\r\r6.2\r\r3.4\r\r5.4\r\r2.3\r\rvirginica\r\r\r\r5.9\r\r3.0\r\r5.1\r\r1.8\r\rvirginica\r\r\r\r\r\rJulia:\nusing RDatasets, DataFrames, GLM\rinclude(\u0026quot;wald_test.jl\u0026quot;)\riris = dataset(\u0026quot;datasets\u0026quot;, \u0026quot;iris\u0026quot;);\r\r1. Joint restrictions\rFirst let’s form a regression model using the iris dataset and name it model.\nR:\nmodel \u0026lt;- lm(Sepal.Length ~ Petal.Length + Petal.Width, iris)\rsummary(model)\r## ## Call:\r## lm(formula = Sepal.Length ~ Petal.Length + Petal.Width, data = iris)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -1.18534 -0.29838 -0.02763 0.28925 1.02320 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 4.19058 0.09705 43.181 \u0026lt; 2e-16 ***\r## Petal.Length 0.54178 0.06928 7.820 9.41e-13 ***\r## Petal.Width -0.31955 0.16045 -1.992 0.0483 * ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 0.4031 on 147 degrees of freedom\r## Multiple R-squared: 0.7663, Adjusted R-squared: 0.7631 ## F-statistic: 241 on 2 and 147 DF, p-value: \u0026lt; 2.2e-16\rJulia:\nmodel = lm(@formula(SepalLength ~ PetalLength + PetalWidth), iris)\rSepalLength ~ 1 + PetalLength + PetalWidth\rCoefficients:\r──────────────────────────────────────────────────────────────────────────────\rEstimate Std. Error t value Pr(\u0026gt;|t|) Lower 95% Upper 95%\r──────────────────────────────────────────────────────────────────────────────\r(Intercept) 4.19058 0.0970459 43.1815 \u0026lt;1e-84 3.9988 4.38237 PetalLength 0.541777 0.0692818 7.81991 \u0026lt;1e-12 0.40486 0.678694 PetalWidth -0.319551 0.160453 -1.99156 0.0483 -0.636642 -0.00245875\r──────────────────────────────────────────────────────────────────────────────\rAs you notice, our model includes 2 regressors and an intercept. We also notice that the estimated coefficient of the variable PetalLength is statistically significant with a p-value close to 0, while the variable PetalWidth is statistically insignificant (at 1% significance level) having a p-value = 0.048.\nIn this situation, assume that we want to test whether the coefficients of these variables are jointly significant different than 0.\nTo do so, we perform a wald test on both of the coefficients.\nR:\nwald_results \u0026lt;- wald.test(Sigma = vcov(model), b = coef(model), Terms = 2:3)\rwald_results\r## Wald test:\r## ----------\r## ## Chi-squared test:\r## X2 = 481.9, df = 2, P(\u0026gt; X2) = 0.0\rJulia:\nwald_results = wald_test(Sigma = vcov(model), b = coef(model), Terms = 2:3)\rWald test:\r----------\rChi-squared test:\rX2 = 481.90740153204536, df = 2, P(\u0026gt; X2) = 2.265360705998325e-105\r\r2. Joint restrictions of all the coefficients except of the intercept\rFor this example, we will create a new variable which is going to be the square of Sepal Length (SepalLength2) and we will fit a new model.\nR:\niris \u0026lt;- data.frame(iris, Sepal.Length2 = iris$Sepal.Length^2)\rmodel2 \u0026lt;- lm(Sepal.Width ~ Sepal.Length + Sepal.Length2, iris)\r\r\rSepal.Length\r\rSepal.Width\r\rPetal.Length\r\rPetal.Width\r\rSpecies\r\rSepal.Length2\r\r\r\r\r\r5.1\r\r3.5\r\r1.4\r\r0.2\r\rsetosa\r\r26.01\r\r\r\r4.9\r\r3.0\r\r1.4\r\r0.2\r\rsetosa\r\r24.01\r\r\r\r4.7\r\r3.2\r\r1.3\r\r0.2\r\rsetosa\r\r22.09\r\r\r\r4.6\r\r3.1\r\r1.5\r\r0.2\r\rsetosa\r\r21.16\r\r\r\r5.0\r\r3.6\r\r1.4\r\r0.2\r\rsetosa\r\r25.00\r\r\r\r5.4\r\r3.9\r\r1.7\r\r0.4\r\rsetosa\r\r29.16\r\r\r\r4.6\r\r3.4\r\r1.4\r\r0.3\r\rsetosa\r\r21.16\r\r\r\r5.0\r\r3.4\r\r1.5\r\r0.2\r\rsetosa\r\r25.00\r\r\r\r4.4\r\r2.9\r\r1.4\r\r0.2\r\rsetosa\r\r19.36\r\r\r\r4.9\r\r3.1\r\r1.5\r\r0.1\r\rsetosa\r\r24.01\r\r\r\r5.4\r\r3.7\r\r1.5\r\r0.2\r\rsetosa\r\r29.16\r\r\r\r4.8\r\r3.4\r\r1.6\r\r0.2\r\rsetosa\r\r23.04\r\r\r\r4.8\r\r3.0\r\r1.4\r\r0.1\r\rsetosa\r\r23.04\r\r\r\r4.3\r\r3.0\r\r1.1\r\r0.1\r\rsetosa\r\r18.49\r\r\r\r5.8\r\r4.0\r\r1.2\r\r0.2\r\rsetosa\r\r33.64\r\r\r\r5.7\r\r4.4\r\r1.5\r\r0.4\r\rsetosa\r\r32.49\r\r\r\r5.4\r\r3.9\r\r1.3\r\r0.4\r\rsetosa\r\r29.16\r\r\r\r5.1\r\r3.5\r\r1.4\r\r0.3\r\rsetosa\r\r26.01\r\r\r\r5.7\r\r3.8\r\r1.7\r\r0.3\r\rsetosa\r\r32.49\r\r\r\r5.1\r\r3.8\r\r1.5\r\r0.3\r\rsetosa\r\r26.01\r\r\r\r5.4\r\r3.4\r\r1.7\r\r0.2\r\rsetosa\r\r29.16\r\r\r\r5.1\r\r3.7\r\r1.5\r\r0.4\r\rsetosa\r\r26.01\r\r\r\r4.6\r\r3.6\r\r1.0\r\r0.2\r\rsetosa\r\r21.16\r\r\r\r5.1\r\r3.3\r\r1.7\r\r0.5\r\rsetosa\r\r26.01\r\r\r\r4.8\r\r3.4\r\r1.9\r\r0.2\r\rsetosa\r\r23.04\r\r\r\r5.0\r\r3.0\r\r1.6\r\r0.2\r\rsetosa\r\r25.00\r\r\r\r5.0\r\r3.4\r\r1.6\r\r0.4\r\rsetosa\r\r25.00\r\r\r\r5.2\r\r3.5\r\r1.5\r\r0.2\r\rsetosa\r\r27.04\r\r\r\r5.2\r\r3.4\r\r1.4\r\r0.2\r\rsetosa\r\r27.04\r\r\r\r4.7\r\r3.2\r\r1.6\r\r0.2\r\rsetosa\r\r22.09\r\r\r\r4.8\r\r3.1\r\r1.6\r\r0.2\r\rsetosa\r\r23.04\r\r\r\r5.4\r\r3.4\r\r1.5\r\r0.4\r\rsetosa\r\r29.16\r\r\r\r5.2\r\r4.1\r\r1.5\r\r0.1\r\rsetosa\r\r27.04\r\r\r\r5.5\r\r4.2\r\r1.4\r\r0.2\r\rsetosa\r\r30.25\r\r\r\r4.9\r\r3.1\r\r1.5\r\r0.2\r\rsetosa\r\r24.01\r\r\r\r5.0\r\r3.2\r\r1.2\r\r0.2\r\rsetosa\r\r25.00\r\r\r\r5.5\r\r3.5\r\r1.3\r\r0.2\r\rsetosa\r\r30.25\r\r\r\r4.9\r\r3.6\r\r1.4\r\r0.1\r\rsetosa\r\r24.01\r\r\r\r4.4\r\r3.0\r\r1.3\r\r0.2\r\rsetosa\r\r19.36\r\r\r\r5.1\r\r3.4\r\r1.5\r\r0.2\r\rsetosa\r\r26.01\r\r\r\r5.0\r\r3.5\r\r1.3\r\r0.3\r\rsetosa\r\r25.00\r\r\r\r4.5\r\r2.3\r\r1.3\r\r0.3\r\rsetosa\r\r20.25\r\r\r\r4.4\r\r3.2\r\r1.3\r\r0.2\r\rsetosa\r\r19.36\r\r\r\r5.0\r\r3.5\r\r1.6\r\r0.6\r\rsetosa\r\r25.00\r\r\r\r5.1\r\r3.8\r\r1.9\r\r0.4\r\rsetosa\r\r26.01\r\r\r\r4.8\r\r3.0\r\r1.4\r\r0.3\r\rsetosa\r\r23.04\r\r\r\r5.1\r\r3.8\r\r1.6\r\r0.2\r\rsetosa\r\r26.01\r\r\r\r4.6\r\r3.2\r\r1.4\r\r0.2\r\rsetosa\r\r21.16\r\r\r\r5.3\r\r3.7\r\r1.5\r\r0.2\r\rsetosa\r\r28.09\r\r\r\r5.0\r\r3.3\r\r1.4\r\r0.2\r\rsetosa\r\r25.00\r\r\r\r7.0\r\r3.2\r\r4.7\r\r1.4\r\rversicolor\r\r49.00\r\r\r\r6.4\r\r3.2\r\r4.5\r\r1.5\r\rversicolor\r\r40.96\r\r\r\r6.9\r\r3.1\r\r4.9\r\r1.5\r\rversicolor\r\r47.61\r\r\r\r5.5\r\r2.3\r\r4.0\r\r1.3\r\rversicolor\r\r30.25\r\r\r\r6.5\r\r2.8\r\r4.6\r\r1.5\r\rversicolor\r\r42.25\r\r\r\r5.7\r\r2.8\r\r4.5\r\r1.3\r\rversicolor\r\r32.49\r\r\r\r6.3\r\r3.3\r\r4.7\r\r1.6\r\rversicolor\r\r39.69\r\r\r\r4.9\r\r2.4\r\r3.3\r\r1.0\r\rversicolor\r\r24.01\r\r\r\r6.6\r\r2.9\r\r4.6\r\r1.3\r\rversicolor\r\r43.56\r\r\r\r5.2\r\r2.7\r\r3.9\r\r1.4\r\rversicolor\r\r27.04\r\r\r\r5.0\r\r2.0\r\r3.5\r\r1.0\r\rversicolor\r\r25.00\r\r\r\r5.9\r\r3.0\r\r4.2\r\r1.5\r\rversicolor\r\r34.81\r\r\r\r6.0\r\r2.2\r\r4.0\r\r1.0\r\rversicolor\r\r36.00\r\r\r\r6.1\r\r2.9\r\r4.7\r\r1.4\r\rversicolor\r\r37.21\r\r\r\r5.6\r\r2.9\r\r3.6\r\r1.3\r\rversicolor\r\r31.36\r\r\r\r6.7\r\r3.1\r\r4.4\r\r1.4\r\rversicolor\r\r44.89\r\r\r\r5.6\r\r3.0\r\r4.5\r\r1.5\r\rversicolor\r\r31.36\r\r\r\r5.8\r\r2.7\r\r4.1\r\r1.0\r\rversicolor\r\r33.64\r\r\r\r6.2\r\r2.2\r\r4.5\r\r1.5\r\rversicolor\r\r38.44\r\r\r\r5.6\r\r2.5\r\r3.9\r\r1.1\r\rversicolor\r\r31.36\r\r\r\r5.9\r\r3.2\r\r4.8\r\r1.8\r\rversicolor\r\r34.81\r\r\r\r6.1\r\r2.8\r\r4.0\r\r1.3\r\rversicolor\r\r37.21\r\r\r\r6.3\r\r2.5\r\r4.9\r\r1.5\r\rversicolor\r\r39.69\r\r\r\r6.1\r\r2.8\r\r4.7\r\r1.2\r\rversicolor\r\r37.21\r\r\r\r6.4\r\r2.9\r\r4.3\r\r1.3\r\rversicolor\r\r40.96\r\r\r\r6.6\r\r3.0\r\r4.4\r\r1.4\r\rversicolor\r\r43.56\r\r\r\r6.8\r\r2.8\r\r4.8\r\r1.4\r\rversicolor\r\r46.24\r\r\r\r6.7\r\r3.0\r\r5.0\r\r1.7\r\rversicolor\r\r44.89\r\r\r\r6.0\r\r2.9\r\r4.5\r\r1.5\r\rversicolor\r\r36.00\r\r\r\r5.7\r\r2.6\r\r3.5\r\r1.0\r\rversicolor\r\r32.49\r\r\r\r5.5\r\r2.4\r\r3.8\r\r1.1\r\rversicolor\r\r30.25\r\r\r\r5.5\r\r2.4\r\r3.7\r\r1.0\r\rversicolor\r\r30.25\r\r\r\r5.8\r\r2.7\r\r3.9\r\r1.2\r\rversicolor\r\r33.64\r\r\r\r6.0\r\r2.7\r\r5.1\r\r1.6\r\rversicolor\r\r36.00\r\r\r\r5.4\r\r3.0\r\r4.5\r\r1.5\r\rversicolor\r\r29.16\r\r\r\r6.0\r\r3.4\r\r4.5\r\r1.6\r\rversicolor\r\r36.00\r\r\r\r6.7\r\r3.1\r\r4.7\r\r1.5\r\rversicolor\r\r44.89\r\r\r\r6.3\r\r2.3\r\r4.4\r\r1.3\r\rversicolor\r\r39.69\r\r\r\r5.6\r\r3.0\r\r4.1\r\r1.3\r\rversicolor\r\r31.36\r\r\r\r5.5\r\r2.5\r\r4.0\r\r1.3\r\rversicolor\r\r30.25\r\r\r\r5.5\r\r2.6\r\r4.4\r\r1.2\r\rversicolor\r\r30.25\r\r\r\r6.1\r\r3.0\r\r4.6\r\r1.4\r\rversicolor\r\r37.21\r\r\r\r5.8\r\r2.6\r\r4.0\r\r1.2\r\rversicolor\r\r33.64\r\r\r\r5.0\r\r2.3\r\r3.3\r\r1.0\r\rversicolor\r\r25.00\r\r\r\r5.6\r\r2.7\r\r4.2\r\r1.3\r\rversicolor\r\r31.36\r\r\r\r5.7\r\r3.0\r\r4.2\r\r1.2\r\rversicolor\r\r32.49\r\r\r\r5.7\r\r2.9\r\r4.2\r\r1.3\r\rversicolor\r\r32.49\r\r\r\r6.2\r\r2.9\r\r4.3\r\r1.3\r\rversicolor\r\r38.44\r\r\r\r5.1\r\r2.5\r\r3.0\r\r1.1\r\rversicolor\r\r26.01\r\r\r\r5.7\r\r2.8\r\r4.1\r\r1.3\r\rversicolor\r\r32.49\r\r\r\r6.3\r\r3.3\r\r6.0\r\r2.5\r\rvirginica\r\r39.69\r\r\r\r5.8\r\r2.7\r\r5.1\r\r1.9\r\rvirginica\r\r33.64\r\r\r\r7.1\r\r3.0\r\r5.9\r\r2.1\r\rvirginica\r\r50.41\r\r\r\r6.3\r\r2.9\r\r5.6\r\r1.8\r\rvirginica\r\r39.69\r\r\r\r6.5\r\r3.0\r\r5.8\r\r2.2\r\rvirginica\r\r42.25\r\r\r\r7.6\r\r3.0\r\r6.6\r\r2.1\r\rvirginica\r\r57.76\r\r\r\r4.9\r\r2.5\r\r4.5\r\r1.7\r\rvirginica\r\r24.01\r\r\r\r7.3\r\r2.9\r\r6.3\r\r1.8\r\rvirginica\r\r53.29\r\r\r\r6.7\r\r2.5\r\r5.8\r\r1.8\r\rvirginica\r\r44.89\r\r\r\r7.2\r\r3.6\r\r6.1\r\r2.5\r\rvirginica\r\r51.84\r\r\r\r6.5\r\r3.2\r\r5.1\r\r2.0\r\rvirginica\r\r42.25\r\r\r\r6.4\r\r2.7\r\r5.3\r\r1.9\r\rvirginica\r\r40.96\r\r\r\r6.8\r\r3.0\r\r5.5\r\r2.1\r\rvirginica\r\r46.24\r\r\r\r5.7\r\r2.5\r\r5.0\r\r2.0\r\rvirginica\r\r32.49\r\r\r\r5.8\r\r2.8\r\r5.1\r\r2.4\r\rvirginica\r\r33.64\r\r\r\r6.4\r\r3.2\r\r5.3\r\r2.3\r\rvirginica\r\r40.96\r\r\r\r6.5\r\r3.0\r\r5.5\r\r1.8\r\rvirginica\r\r42.25\r\r\r\r7.7\r\r3.8\r\r6.7\r\r2.2\r\rvirginica\r\r59.29\r\r\r\r7.7\r\r2.6\r\r6.9\r\r2.3\r\rvirginica\r\r59.29\r\r\r\r6.0\r\r2.2\r\r5.0\r\r1.5\r\rvirginica\r\r36.00\r\r\r\r6.9\r\r3.2\r\r5.7\r\r2.3\r\rvirginica\r\r47.61\r\r\r\r5.6\r\r2.8\r\r4.9\r\r2.0\r\rvirginica\r\r31.36\r\r\r\r7.7\r\r2.8\r\r6.7\r\r2.0\r\rvirginica\r\r59.29\r\r\r\r6.3\r\r2.7\r\r4.9\r\r1.8\r\rvirginica\r\r39.69\r\r\r\r6.7\r\r3.3\r\r5.7\r\r2.1\r\rvirginica\r\r44.89\r\r\r\r7.2\r\r3.2\r\r6.0\r\r1.8\r\rvirginica\r\r51.84\r\r\r\r6.2\r\r2.8\r\r4.8\r\r1.8\r\rvirginica\r\r38.44\r\r\r\r6.1\r\r3.0\r\r4.9\r\r1.8\r\rvirginica\r\r37.21\r\r\r\r6.4\r\r2.8\r\r5.6\r\r2.1\r\rvirginica\r\r40.96\r\r\r\r7.2\r\r3.0\r\r5.8\r\r1.6\r\rvirginica\r\r51.84\r\r\r\r7.4\r\r2.8\r\r6.1\r\r1.9\r\rvirginica\r\r54.76\r\r\r\r7.9\r\r3.8\r\r6.4\r\r2.0\r\rvirginica\r\r62.41\r\r\r\r6.4\r\r2.8\r\r5.6\r\r2.2\r\rvirginica\r\r40.96\r\r\r\r6.3\r\r2.8\r\r5.1\r\r1.5\r\rvirginica\r\r39.69\r\r\r\r6.1\r\r2.6\r\r5.6\r\r1.4\r\rvirginica\r\r37.21\r\r\r\r7.7\r\r3.0\r\r6.1\r\r2.3\r\rvirginica\r\r59.29\r\r\r\r6.3\r\r3.4\r\r5.6\r\r2.4\r\rvirginica\r\r39.69\r\r\r\r6.4\r\r3.1\r\r5.5\r\r1.8\r\rvirginica\r\r40.96\r\r\r\r6.0\r\r3.0\r\r4.8\r\r1.8\r\rvirginica\r\r36.00\r\r\r\r6.9\r\r3.1\r\r5.4\r\r2.1\r\rvirginica\r\r47.61\r\r\r\r6.7\r\r3.1\r\r5.6\r\r2.4\r\rvirginica\r\r44.89\r\r\r\r6.9\r\r3.1\r\r5.1\r\r2.3\r\rvirginica\r\r47.61\r\r\r\r5.8\r\r2.7\r\r5.1\r\r1.9\r\rvirginica\r\r33.64\r\r\r\r6.8\r\r3.2\r\r5.9\r\r2.3\r\rvirginica\r\r46.24\r\r\r\r6.7\r\r3.3\r\r5.7\r\r2.5\r\rvirginica\r\r44.89\r\r\r\r6.7\r\r3.0\r\r5.2\r\r2.3\r\rvirginica\r\r44.89\r\r\r\r6.3\r\r2.5\r\r5.0\r\r1.9\r\rvirginica\r\r39.69\r\r\r\r6.5\r\r3.0\r\r5.2\r\r2.0\r\rvirginica\r\r42.25\r\r\r\r6.2\r\r3.4\r\r5.4\r\r2.3\r\rvirginica\r\r38.44\r\r\r\r5.9\r\r3.0\r\r5.1\r\r1.8\r\rvirginica\r\r34.81\r\r\r\r\r\rJulia:\niris[:SepalLength2] = iris.SepalLength .^ 2\rmodel2 = lm(@formula(SepalWidth ~ SepalLength + SepalLength2), iris)\rSepalWidth ~ 1 + SepalLength + SepalLength2\rCoefficients:\r─────────────────────────────────────────────────────────────────────────────────\rEstimate Std. Error t value Pr(\u0026gt;|t|) Lower 95% Upper 95%\r─────────────────────────────────────────────────────────────────────────────────\r(Intercept) 6.41584 1.58499 4.04787 \u0026lt;1e-4 3.28352 9.54815 SepalLength -1.08556 0.536246 -2.02437 0.0447 -2.14531 -0.0258139\rSepalLength2 0.0857066 0.044755 1.91502 0.0574 -0.00273979 0.174153 ─────────────────────────────────────────────────────────────────────────────────\rIn essence, this is the F-test which is most of the times printed at the bottom of a regression accompanied by its degrees of freedom and the p-value. This test informs us, whether the regressors are jointly equal to zero, and thus if the regression as a whole is useless. In fact, in this case, simply the (unconditional) mean of the dependent variable would have been as good predictor as all of these variables together.\nIn R, so far so good. As you can see, at the bottom line of summary(model2) we have what we want.\nR:\nsummary(model2)\r## ## Call:\r## lm(formula = Sepal.Width ~ Sepal.Length + Sepal.Length2, data = iris)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -1.13070 -0.26310 -0.02446 0.25728 1.38725 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 6.41584 1.58499 4.048 8.33e-05 ***\r## Sepal.Length -1.08556 0.53625 -2.024 0.0447 * ## Sepal.Length2 0.08571 0.04476 1.915 0.0574 . ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 0.4304 on 147 degrees of freedom\r## Multiple R-squared: 0.03783, Adjusted R-squared: 0.02474 ## F-statistic: 2.89 on 2 and 147 DF, p-value: 0.05877\rOn the other hand, the regression output in Julia doesn’t provide so much information. To retrieve the information about the F-test we will need to do the following things. What we are actually going to do is to use ANOVA which is an F-test and compare our model (sometimes called full model) with the null model which is a regression without any independent variables except from the constant term. So, first we have to create the null model and then perform an F-test (ANOVA) comparing these two models (using the ftest function from the GLM package).\nJulia:\nnullmodel2 = lm(@formula(SepalWidth ~ 1), iris)\rftest(model2.model, nullmodel2.model)\r Res. DOF DOF ΔDOF SSR ΔSSR R² ΔR² F* p(\u0026gt;F)\rModel 1 147 4 27.2362 0.0378 Model 2 149 2 -2 28.3069 -1.0708 0.0000 0.0378 2.8895 0.0588\rSpeaking about Julia, not so straight forward, right? Now, what if we could skip all this workaround and just perform a restriction, jointly to all the coefficients except from the intercept? That’s right! We can use our new Julia function wald_test exactly the same way as we did before.\nJulia:\nwald_results = wald_test(Sigma = vcov(model2), b = coef(model2), Terms = 2:3)\rWald test:\r----------\rChi-squared test:\rX2 = 5.779097987201187, df = 2, P(\u0026gt; X2) = 0.05560128349216448\rBut as you are about to notice, our result is a Chi square (Χ^2) test instead of an F-test. If we want to see the equivalent F-test, using some basic knowledge from distribution theory, we can go from a Chi square distribution to an F distribution using the following formula:\n\\[\\frac{\\chi^2}{df} = F\\]\nWhere the degrees of freedom from the Chi square distribution is the number of restrictions, and this is also the numerator degrees of freedom from the equivalent F distribution.\nJulia:\nwald_chi2 = wald_results.result[\u0026quot;chi2\u0026quot;].chi2\rwald_df = wald_results.result[\u0026quot;chi2\u0026quot;].df\rfstat = wald_chi2 / wald_df\r2.8895489936005934\rNow that we have the F statistic, we could calculate the p-value which corresponds to the value of the F statistic on the pdf (probability density function) of the F distribution. But this is already too much work for something like this… Once again, we can skip this mess just by asking our new wald_test function to perform an F test for our joint restrictions. All we need is to add the denominator degrees of freedom dendf.\nJulia:\ndendf = nrow(iris)-length(coef(model2))\rwald_results = wald_test(Sigma = vcov(model2), b = coef(model2), Terms = 2:3, df = dendf)\rWald test:\r----------\rChi-squared test:\rX2 = 5.779097987201187, df = 2, P(\u0026gt; X2) = 0.05560128349216448\rF test:\rW = 2.8895489936005934, df1 = 2, df2 = 147, P(\u0026gt; W) = 0.05876576520988747\rAs you notice, the p-values of the \\(x^2\\) and the F tests are very close but not identical. But as the denominator degrees of freedom is getting larger (i.e. as the number of observations rises or the number of coefficients is getting smaller), the p-value of the F test is getting closer and closer to the p-value of the \\(x^2\\) test.\n\r3. Joint restrictions of all the coefficients including the intercept\rWhen I faced the previous problem I thought I could take the long way and perform an ANOVA, just to get the job done. That was until I faced the next problem. Consider the problem where you want to test whether all the regression’s coefficients including the intercept are jointly equal to zero. What is the null model in this case? It’s not even the sample mean of the dependent variable as in the previous case. And would it even be nested to our full model? This is the situation which led me to create the wald test function for Julia.\nSee how easy it is to test if all the coefficients are equal to 0 or whether the intercept, the first and the second coefficients are respectively equal to 4.2, 0.54 and -0.3. In both cases, the \\(x^2-test\\)and the F-test come to the same conclusion.\nJulia:\nmodel\rSepalLength ~ 1 + PetalLength + PetalWidth\rCoefficients:\r──────────────────────────────────────────────────────────────────────────────\rEstimate Std. Error t value Pr(\u0026gt;|t|) Lower 95% Upper 95%\r──────────────────────────────────────────────────────────────────────────────\r(Intercept) 4.19058 0.0970459 43.1815 \u0026lt;1e-84 3.9988 4.38237 PetalLength 0.541777 0.0692818 7.81991 \u0026lt;1e-12 0.40486 0.678694 PetalWidth -0.319551 0.160453 -1.99156 0.0483 -0.636642 -0.00245875\r──────────────────────────────────────────────────────────────────────────────\rdendf = nrow(iris)-length(coef(model))\rwald_results = wald_test(Sigma = vcov(model), b = coef(model), Terms = 1:3, df = dendf).result\rWald test:\r----------\rChi-squared test:\rX2 = 32008.931513284944, df = 3, P(\u0026gt; X2) = 0.0\rF test:\rW = 10669.643837761649, df1 = 3, df2 = 147, P(\u0026gt; W) = 1.0022050012971983e-171\rwald_results = wald_test(Sigma = vcov(model), b = coef(model), Terms = 1:3, H0 = [4.2, 0.54, -0.3], df = dendf).result\rWald test:\r----------\rChi-squared test:\rX2 = 0.763308780543053, df = 3, P(\u0026gt; X2) = 0.858221426416421\rF test:\rW = 0.25443626018101767, df1 = 3, df2 = 147, P(\u0026gt; W) = 0.8580771658399398\rFeel free to download, modify and use the code!\nComments of all kinds are more than welcome!\n\r\rThe wald_test function requires the Distributions package which is loaded automatically upon the inclusion of the wald_test.jl file.↩\n\r\r\r","date":1569456000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569456000,"objectID":"c73203fd7c076ae82471e4b72e6282e5","permalink":"/post/wald-test-julia/wald-test-julia/","publishdate":"2019-09-26T00:00:00Z","relpermalink":"/post/wald-test-julia/wald-test-julia/","section":"post","summary":"A new function for wald-test in Julia. Comparison with the R code and examples using Chi-square and F tests.","tags":["Julia","R","statistics"],"title":"Wald-test function in Julia","type":"post"},{"authors":null,"categories":["do it right"],"content":"\r\rThis is the first post of the series do it right. This series consist of posts that aim to give an alternative and simple view on usual misunderstandings and misuses of methods.\nANOVA is taught in the university as one of our first steps in statistics after some basic probability theory, distributions and t-test. It is used as a means of measuring the differences among sample means and is practically an F-test. Here we will examine the use of ANOVA (F-test) in testing nested models, or in other words, in testing whether a factor in the regression is needed or not. This is a typical step when we try to build a model but although it is a trivial routine, how many of us really consider the three types of ANOVA and apply the correct one in each case? Or even, how many know about these three different types?\nIn this example I will use the samara dataset. As Ryan et al (1994) describe:\n\rIn autumn, small winged fruit called samara fall off maple trees, spinning as they go.\n\rDescription of the problem:\n\rA forest scientist is interested in studying the relationship between the terminal velocity of falling maple samaras and a measure of their size and weight known as disk loading. A samara is the winged fruit that falls to the ground with a helicopter-like motion. The disk loading is a quantity related to helicopter aerodynamics. In an experiment samaras were randomly selected from each of three distinct trees (of the same species). The disk loading (loading) for each samara was determined and the terminal velocity (velocity) was measured in the laboratory. The forest scientist conducting the study hypothesizes that there is a linear relationship between terminal velocity and disk loading. The scientist wishes to determine whether the relationship is the same for each tree.\n\rIn other words, we want to determine whether the samara fruits fall with the same velocity from each tree, taking into account the size of the fruit in order for the comparison to be between fruits of the same size.\nFirst, lets read the data and remove the observation which has NA. Then, we turn the variable Tree into a factor as we want it to represent the three trees and not some arbitrary numbers.\nlibrary(ggplot2)\rlibrary(gridExtra)\rlibrary(car)\rsamara \u0026lt;- read.table(\u0026quot;http://www.statsci.org/data/general/samara.txt\u0026quot;, header=TRUE)\rsamara \u0026lt;- samara[complete.cases(samara), ]\rsamara$Tree \u0026lt;- as.factor(samara$Tree)\r\r\rTree\r\rLoad\r\rVelocity\r\r\r\r\r\r1\r\r0.239\r\r1.34\r\r\r\r1\r\r0.208\r\r1.06\r\r\r\r1\r\r0.223\r\r1.14\r\r\r\r1\r\r0.224\r\r1.13\r\r\r\r1\r\r0.246\r\r1.35\r\r\r\r1\r\r0.213\r\r1.23\r\r\r\r1\r\r0.198\r\r1.23\r\r\r\r1\r\r0.219\r\r1.15\r\r\r\r1\r\r0.241\r\r1.25\r\r\r\r1\r\r0.210\r\r1.24\r\r\r\r1\r\r0.224\r\r1.34\r\r\r\r1\r\r0.269\r\r1.35\r\r\r\r2\r\r0.238\r\r1.20\r\r\r\r2\r\r0.206\r\r1.06\r\r\r\r2\r\r0.172\r\r0.88\r\r\r\r2\r\r0.235\r\r1.24\r\r\r\r2\r\r0.247\r\r1.37\r\r\r\r2\r\r0.239\r\r1.37\r\r\r\r2\r\r0.233\r\r1.43\r\r\r\r2\r\r0.234\r\r1.32\r\r\r\r2\r\r0.189\r\r0.99\r\r\r\r2\r\r0.192\r\r1.00\r\r\r\r2\r\r0.209\r\r1.12\r\r\r\r2\r\rNA\r\rNA\r\r\r\r3\r\r0.192\r\r0.91\r\r\r\r3\r\r0.200\r\r1.13\r\r\r\r3\r\r0.175\r\r1.00\r\r\r\r3\r\r0.187\r\r0.98\r\r\r\r3\r\r0.181\r\r0.96\r\r\r\r3\r\r0.195\r\r0.88\r\r\r\r3\r\r0.155\r\r0.81\r\r\r\r3\r\r0.179\r\r0.91\r\r\r\r3\r\r0.184\r\r1.00\r\r\r\r3\r\r0.177\r\r0.87\r\r\r\r3\r\r0.177\r\r1.02\r\r\r\r3\r\r0.186\r\r0.94\r\r\r\r\r\rFrom a simple box-plot we can see that the velocity is different between the trees. Particularly, tree 3 seems to have the lowest velocity, while trees 1 and 2 about the same. The box-plot and the scatter-plot also show that tree 2 has a wide range of velocities.\n# Box-plot\rbox_plot \u0026lt;- ggplot(samara, aes(x=Tree, y=Velocity, color=Tree)) +\rgeom_boxplot()\r# Scatter-plot clustered\rscatter_plot_clustered \u0026lt;- ggplot(samara, aes(x=Load, y=Velocity, shape=Tree, color=Tree)) +\rgeom_point() + stat_ellipse()\r# plot together\rgrid.arrange(box_plot, scatter_plot_clustered, nrow=2)\rIs this difference in velocity because of the size of the samara fruits or the tree also affects it? Would we expect a samara of specific load to fall with the same velocity from tree 1 as it would have fallen from tree 3? As a quick answer I would say, yes, there is no magic in the trees. But lets see what statistics have to say.\nThe first model considers only the factor Tree. The reference level is Tree1, and as we can see the coefficient of Tree3 is statistically significant which means that the mean velocity of Tree3 is significantly different from the mean velocity of Tree1 (the reference level) while Tree2 doesn’t differ. The ANOVA also indicates that total factor Tree is needed in the model as it appears to be statistically significant.\nmodel_tree \u0026lt;- lm(Velocity~Tree, data=samara)\rsummary(model_tree)\r## ## Call:\r## lm(formula = Velocity ~ Tree, data = samara)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -0.300000 -0.082500 0.005833 0.087500 0.250000 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 1.23417 0.03676 33.571 \u0026lt; 2e-16 ***\r## Tree2 -0.05417 0.05316 -1.019 0.316 ## Tree3 -0.28333 0.05199 -5.450 5.37e-06 ***\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 0.1274 on 32 degrees of freedom\r## Multiple R-squared: 0.5097, Adjusted R-squared: 0.479 ## F-statistic: 16.63 on 2 and 32 DF, p-value: 1.117e-05\ranova(model_tree, test=\u0026#39;F\u0026#39;)\r## Analysis of Variance Table\r## ## Response: Velocity\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Tree 2 0.53942 0.269708 16.63 1.117e-05 ***\r## Residuals 32 0.51898 0.016218 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rBut we have noticed that tree 3 has smaller fruits than the other two trees and thus with smaller load and this is probably what makes it to differe, not the tree itself.\nTo tests this hypothesis, lets build the full model. This model consists of the variables Tree, Load but also their interaction. ANOVA indicates that the interaction is statistically insignificant (at a=5%).\nfull_model \u0026lt;- lm(Velocity~Tree*Load, data=samara)\rsummary(full_model)\r## ## Call:\r## lm(formula = Velocity ~ Tree * Load, data = samara)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -0.120023 -0.049465 -0.001298 0.049938 0.145571 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.5414 0.2632 2.057 0.0488 *\r## Tree2 -0.8408 0.3356 -2.505 0.0181 *\r## Tree3 -0.2987 0.4454 -0.671 0.5078 ## Load 3.0629 1.1599 2.641 0.0132 *\r## Tree2:Load 3.7343 1.5000 2.490 0.0188 *\r## Tree3:Load 0.8205 2.2837 0.359 0.7220 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 0.07554 on 29 degrees of freedom\r## Multiple R-squared: 0.8436, Adjusted R-squared: 0.8167 ## F-statistic: 31.29 on 5 and 29 DF, p-value: 7.656e-11\ranova(full_model, test=\u0026#39;F\u0026#39;)\r## Analysis of Variance Table\r## ## Response: Velocity\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Tree 2 0.53942 0.269708 47.262 7.488e-10 ***\r## Load 1 0.31554 0.315542 55.294 3.406e-08 ***\r## Tree:Load 2 0.03795 0.018975 3.325 0.05011 . ## Residuals 29 0.16549 0.005707 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rIn the next model we exclude the interaction as ANOVA suggested. We notice now that controlling for the Load, the Tree3 seems to have no significant difference from the Tree1 as it is statistically insignificant. On the other hand Load does matter. But remember that the regression output shows the difference between each level and the reference level (Tree1). To know if the total factor Tree is needed or not we take a look at the ANOVA table where it seems that the variables Tree and Load are both significant. This means that the size of the samara fruit matters but also the tree!\nmodel_tree_load \u0026lt;- lm(Velocity~Tree + Load, data=samara)\rsummary(model_tree_load)\r## ## Call:\r## lm(formula = Velocity ~ Tree + Load, data = samara)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -0.13572 -0.06027 -0.01576 0.05973 0.17130 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.07561 0.16871 0.448 0.657 ## Tree2 -0.01047 0.03440 -0.304 0.763 ## Tree3 -0.05879 0.04629 -1.270 0.213 ## Load 5.12257 0.73875 6.934 8.88e-08 ***\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 0.08101 on 31 degrees of freedom\r## Multiple R-squared: 0.8078, Adjusted R-squared: 0.7892 ## F-statistic: 43.43 on 3 and 31 DF, p-value: 3.261e-11\ranova(model_tree_load, test=\u0026#39;F\u0026#39;)\r## Analysis of Variance Table\r## ## Response: Velocity\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Tree 2 0.53942 0.269708 41.098 1.913e-09 ***\r## Load 1 0.31554 0.315542 48.082 8.884e-08 ***\r## Residuals 31 0.20344 0.006563 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rSo, why this inconsistency of the ANOVA results? The regression results suggest that neither Tree2 nor Tree3 differ from the reference level (Tree1) but ANOVA suggests that the total factor Tree which has three levels (Tree1, Tree2, Tree3) is useful in the model.\nThe three types of ANOVA\rType I: SS(A), SS(B|A), SS(AB|A,B)\nThis is what R uses by default. This means that ANOVA performs the F-test in each term sequentially starting from the first. In our previous example of the model model_tree_load what is done is that ANOVA first performs the F-test in the variable Tree and it turns out to be significant for the same reasons why ANOVA for the model_tree indicates the variable Tree as significant. This is the phase SS(A), in our case SS(Tree).\nAfter this, ANOVA tests the variable Load conditional on Tree (given Tree). This is the phase SS(B|A), in our case SS(Load|Tree).\nWhat is happening here is that while the regression is simultaneously taking into account both Tree and Load, ANOVA doesn’t!\nOne solution could be to reverse the order of the variables in the regression. This way, the sequence in ANOVA is: SS(Load), SS(Tree|Load). As we can see, the total factor Tree accounting for the Load is now insignificant.\nmodel_tree_load2 \u0026lt;- lm(Velocity~Load + Tree, data=samara)\ranova(model_tree_load2, test=\u0026#39;F\u0026#39;)\r## Analysis of Variance Table\r## ## Response: Velocity\r## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Load 1 0.84364 0.84364 128.5517 1.471e-12 ***\r## Tree 2 0.01132 0.00566 0.8626 0.4319 ## Residuals 31 0.20344 0.00656 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rType II: SS(A|B), SS(B|A)\nA more elegant way of doing this is to perform a type II ANOVA. This way each variable will be tested given the others. The function Anova from the package car can help us perform the type II ANOVA.\nOne can notice that the test results for the varaibles Load and Tree are now the same as those of the type I ANOVA on the models model_tree_load and model_tree_load2 accordingly, where Load and Tree are the second variable in order in each case.\nAnova(model_tree_load, type=\u0026quot;II\u0026quot;, test.statistic=\u0026#39;F\u0026#39;)\r## Anova Table (Type II tests)\r## ## Response: Velocity\r## Sum Sq Df F value Pr(\u0026gt;F) ## Tree 0.011322 2 0.8626 0.4319 ## Load 0.315542 1 48.0817 8.884e-08 ***\r## Residuals 0.203441 31 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rType III: SS(A|B,AB), SS(B|A,AB)\nThe type III ANOVA differs from the type II as it also accounts for the itneraction term. In our case there is no interaction so the results for Tree and Load would be the same.\nAnova(model_tree_load, type=\u0026quot;III\u0026quot;, test.statistic=\u0026#39;F\u0026#39;)\r## Anova Table (Type III tests)\r## ## Response: Velocity\r## Sum Sq Df F value Pr(\u0026gt;F) ## (Intercept) 0.001318 1 0.2009 0.6571 ## Tree 0.011322 2 0.8626 0.4319 ## Load 0.315542 1 48.0817 8.884e-08 ***\r## Residuals 0.203441 31 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r\rConclusion\rIn conclusion, we found out that the Tree doesn’t affect the velocity, only the Load does. So for samara fruits of the same Load, the velocity would be the same for every tree. The reason why the velocity in the Tree 3 is smaller is because it has smaller fruits.\nIs this so important after all? Are these just details? Or is it an essential knowledge about how ANOVA works?\nIn my opinion, the most important thing is to understand how something works. Then, it is not anymore a fuzzy type I, II, III, but a crystal clear situation where the order does matter.\nThe previous example could be a simple toy example for undergraduate students. But we saw how easy was to produce misleading results for someone who hasn’t heard of the above.\nNext time, do it right!\n\rSources\rRyan, B.F., Joiner, B.L., and Rogosa, D. (1994). Minitab Handbook 3rd edition. Duxbury Press.\n\r","date":1549843200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549843200,"objectID":"c5f21e6cd103ad68a2d88b0b9f968031","permalink":"/post/anova-types/anova-types/","publishdate":"2019-02-11T00:00:00Z","relpermalink":"/post/anova-types/anova-types/","section":"post","summary":"Even the most *basic* statistical tests like ANOVA can lead to misleading results if we don't fully understand them. Example using samara, the maple tree fruit.","tags":["R","statistics"],"title":"Three types of ANOVA","type":"post"},{"authors":["Kleanthis Natsiopoulos","Alexandra Livada"],"categories":null,"content":"","date":1544911200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544911200,"objectID":"f044afd6d6d76027fa149b2e5c9bc928","permalink":"/publication/tis-ardl-conference-poster/","publishdate":"2018-12-16T00:00:00+02:00","relpermalink":"/publication/tis-ardl-conference-poster/","section":"publication","summary":"The purpose is to explore the cointegrating relationships between the 1% top income share and the macroeconomic factors of credit, education, GDP, inflation, population growth and trade in order to reveal if there is a long-run relationship. This relationship is tested for four different countries: Greece, France, USA and UK. We are trying to see if the income inequality is driven by the same factors and in the same way for such different economies. The popular ARDL bounds test for cointegration is used for this analysis. There are strong indications supporting the existence of such a relationship for the cases of France and Greece. For the case of USA, the test suggests the existence of a long-run relationship but a simple graphical inspection is enough to tell us that this is a false positive alarm (type I error) as this is a degenerate relationship. Finally, for the case of UK a not well-defined model supports the longrun relationship hypothesis but a more carefully designed model is against this decision.","tags":["Econometrics","Time-Series","Cointegration"],"title":"An ARDL approach for income inequality: Case studies for France, Greece, UK and USA","type":"publication"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne\r Two\r Three\r\nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]